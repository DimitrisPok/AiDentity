{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the data from lfw dataset set is augmented using techniques such as flipping, dynamic rotation, color jittering, \n",
    "# and edge enhancement. The augmentation techniques are applied to people with min 20 images.\n",
    "\n",
    "import sqlite3\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import imutils\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Load the data using sklearn\n",
    "lfw_dataset = fetch_lfw_people(data_home='./LFW/', min_faces_per_person=20, download_if_missing=True, color=True)\n",
    "\n",
    "# Get the path to the raw images\n",
    "raw_images_path = os.path.join('./LFW/', \"lfw_home/lfw_funneled\")\n",
    "\n",
    "# Load raw images\n",
    "raw_images = []\n",
    "raw_names = os.listdir(raw_images_path)\n",
    "\n",
    "# Connecting to the original SQLite database\n",
    "conn_original = sqlite3.connect('lfw_dataset.db')\n",
    "cursor_original = conn_original.cursor()\n",
    "\n",
    "# Connecting to the new SQLite database for augmented images\n",
    "conn_augmented = sqlite3.connect('lfw_augmented_dataset.db')\n",
    "cursor_augmented = conn_augmented.cursor()\n",
    "\n",
    "# Connecting to the new SQLite database for augmented images\n",
    "conn_raw = sqlite3.connect('lfw_raw_dataset.db')\n",
    "cursor_raw = conn_raw.cursor()\n",
    "\n",
    "# Drop the existing 'faces' table if it exists in the augmented database\n",
    "cursor_original.execute('DROP TABLE IF EXISTS faces')\n",
    "\n",
    "# Drop the existing 'faces' table if it exists in the augmented database\n",
    "cursor_augmented.execute('DROP TABLE IF EXISTS faces')\n",
    "\n",
    "# Drop the existing 'faces' table if it exists in the augmented database\n",
    "cursor_raw.execute('DROP TABLE IF EXISTS faces')\n",
    "\n",
    "# Creating a new 'faces' table in the augmented database\n",
    "cursor_augmented.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS faces (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        target INTEGER,\n",
    "        name TEXT NOT NULL,\n",
    "        image BLOB NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# creating a table\n",
    "cursor_original.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS faces (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        target INTEGER,\n",
    "        name TEXT NOT NULL,\n",
    "        image BLOB NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# creating a table\n",
    "cursor_raw.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS faces (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        target INTEGER,\n",
    "        name TEXT NOT NULL,\n",
    "        raw_image BLOB NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "\n",
    "image_index = -1\n",
    "total_images = 0\n",
    "total_raw_images = 0\n",
    "\n",
    "\n",
    "# Inserting the targets, names, and images into the table\n",
    "for images in lfw_dataset.images:\n",
    "    # Convert the image data to bytes\n",
    "    image_bytes = pickle.dumps(images)\n",
    "    image_index += 1\n",
    "    total_images += 1\n",
    "    # Get the target index for the specified image\n",
    "    target_index = lfw_dataset.target[image_index]\n",
    "    # Get the corresponding name from target_names\n",
    "    name = lfw_dataset.target_names[target_index]\n",
    "    # Insert the record into the database with target as id\n",
    "    cursor_original.execute(\"INSERT INTO faces (target, name, image) VALUES (?, ?, ?)\", (int(target_index), name, image_bytes))\n",
    "\n",
    "# Commit the changes to the augmented database\n",
    "conn_original.commit()\n",
    "\n",
    "# Iterate through all people in the dataset\n",
    "for target_index, name in enumerate(lfw_dataset.target_names):\n",
    "    # Replace spaces with underscores in the name for directory lookup\n",
    "    raw_image_directory_name = name.replace(\" \", \"_\")\n",
    "\n",
    "    # Find the matching raw image directory\n",
    "    raw_image_path = os.path.join(raw_images_path, raw_image_directory_name)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(raw_image_path):\n",
    "        # Iterate through all raw images in the directory\n",
    "        for raw_image_name in os.listdir(raw_image_path):\n",
    "            # Exclude images containing \"original\"\n",
    "            if \"original\" not in raw_image_name:\n",
    "                raw_image_file = os.path.join(raw_image_path, raw_image_name)\n",
    "                raw_image = cv2.imread(raw_image_file)\n",
    "\n",
    "                # Convert the raw image to bytes\n",
    "                raw_image_bytes = pickle.dumps(raw_image, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                total_raw_images += 1\n",
    "\n",
    "                # Insert the record into the database with target as id\n",
    "                cursor_raw.execute(\"INSERT INTO faces (target, name, raw_image) VALUES (?, ?, ?)\",\n",
    "                                        (int(target_index), name, raw_image_bytes))\n",
    "    else:\n",
    "        # Handle the case where the directory does not exist\n",
    "        print(f\"No raw image directory found for {name}\")\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn_raw.commit()\n",
    "\n",
    "# Print the total number of images and raw images extracted\n",
    "print(f\"Total number of images: {total_images}\")\n",
    "print(f\"Total number of raw images: {total_raw_images}\")\n",
    "\n",
    "# Retrieve unique names from the original database\n",
    "cursor_original.execute('SELECT DISTINCT name FROM faces')\n",
    "unique_names = [row[0] for row in cursor_original.fetchall()]\n",
    "\n",
    "# Retrieve data from the original database\n",
    "cursor_original.execute('SELECT target, name, image FROM faces')\n",
    "rows_original = cursor_original.fetchall()\n",
    "\n",
    "# Function for edge enhancement using Laplacian filter\n",
    "def enhance_edges(image):\n",
    "    # Convert the image to BGR if it's in RGB format\n",
    "    if image.shape[-1] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Laplacian filter\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "\n",
    "    # Convert back to RGB or BGR\n",
    "    if image.shape[-1] == 3:\n",
    "        sharp_image = np.clip(image - 0.7 * laplacian[:, :, np.newaxis], 0, 255).astype('uint8')\n",
    "    else:\n",
    "        sharp_image = np.clip(gray - 0.7 * laplacian, 0, 255).astype('uint8')\n",
    "\n",
    "    return sharp_image\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.BatchNorm2d(in_features),\n",
    "                      nn.ReLU(),\n",
    "                      nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.BatchNorm2d(in_features)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(3, ngf, 7),\n",
    "                 nn.BatchNorm2d(ngf),\n",
    "                 nn.ReLU()]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = ngf\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                      nn.BatchNorm2d(out_features),\n",
    "                      nn.ReLU()]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                      nn.BatchNorm2d(out_features),\n",
    "                      nn.ReLU()]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(ngf, 3, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def apply_pretrained_model(image):\n",
    "\n",
    "    # Load the age progression model\n",
    "    model = Generator(ngf=32, n_residual_blocks=9)\n",
    "    ckpt = torch.load('/Users/sadhanaanandan/Fast-AgingGAN/pretrained_model/state_dict.pth', map_location='cpu')\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    # Define image transformations\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    image = trans(Image.fromarray((image * 255).astype('uint8')).convert('RGB')).unsqueeze(0)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        result = model(image)\n",
    "    \n",
    "    # Convert the result back to a NumPy array\n",
    "    result = result.squeeze().cpu().numpy().transpose((1, 2, 0))\n",
    "   \n",
    "    # Postprocess if necessary (e.g., denormalization)\n",
    "    result = ((result + 1) / 2.0 * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "    return result\n",
    "\n",
    "# Assuming each row in 'rows' is a tuple (target, name, image_bytes)\n",
    "def convert_to_rgb(image_data):\n",
    "    # Convert BGR to RGB\n",
    "    rgb_image = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_image\n",
    "\n",
    "def save_image_to_database(cursor, target, name, image_bytes):\n",
    "\n",
    "    cursor.execute(\"INSERT INTO faces (target, name, image) VALUES (?, ?, ?)\", (int(target), name, image_bytes))\n",
    "\n",
    "# Create an instance of the MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Initialize counters\n",
    "original_images_count = 0\n",
    "flipped_images_count = 0\n",
    "rotated_images_count = 0\n",
    "jittered_images_count = 0\n",
    "enhanced_images_count = 0\n",
    "aged_images_count = 0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Function for edge enhancement using Laplacian filter\n",
    "def enhance_edges(image):\n",
    "    # Apply Laplacian filter\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharp_image = np.clip(image - 0.7 * laplacian, 0, 255).astype('uint8')\n",
    "    return sharp_image\n",
    "\"\"\"\n",
    "\n",
    "# Process each image for the person\n",
    "for name in tqdm(unique_names, desc='Processing images'):\n",
    "    # Retrieve data for the current person from the original database\n",
    "    cursor_original.execute('SELECT target, name, image FROM faces WHERE name = ?', (name,))\n",
    "    person_images_original = cursor_original.fetchall()\n",
    "\n",
    "    # Determine the number of images to process for this person\n",
    "    max_images_to_process = min(50, len(person_images_original))\n",
    "    \n",
    "    # Process images if there are 70 or fewer images\n",
    "    if len(person_images_original) <= 30:\n",
    "        for idx, row_original in enumerate(person_images_original):\n",
    "            target, _, original_image_bytes = row_original\n",
    "\n",
    "            # Convert the image bytes back to a NumPy array\n",
    "            original_image = pickle.loads(original_image_bytes)\n",
    "\n",
    "            # Save original image to the augmented database in RGB format\n",
    "            original_image_rgb = (original_image * 255).astype('uint8')\n",
    "            original_image_bytes = pickle.dumps(original_image_rgb)\n",
    "            save_image_to_database(cursor_augmented, target, name, original_image_bytes)\n",
    "\n",
    "            # Increment original images count\n",
    "            original_images_count += 1\n",
    "\n",
    "            # Save flipped image to the augmented database in RGB format\n",
    "            flipped_image = cv2.flip(original_image_rgb, 1)\n",
    "            flipped_image_bytes = pickle.dumps(flipped_image)\n",
    "            save_image_to_database(cursor_augmented, target, name, flipped_image_bytes)\n",
    "\n",
    "            flipped_images_count += 1\n",
    "            \n",
    "            # Apply dynamic rotation to the original image\n",
    "            rotation_angle = random.uniform(-30, 30)  # Random rotation angle between -30 and 30 degrees\n",
    "            rotated_image = imutils.rotate(original_image_rgb, angle=rotation_angle)\n",
    "\n",
    "            # Save rotated image to the augmented database in RGB format\n",
    "            rotated_image_bytes = pickle.dumps(rotated_image)\n",
    "            save_image_to_database(cursor_augmented, target, name, rotated_image_bytes)\n",
    "\n",
    "            rotated_images_count += 1\n",
    "\n",
    "            # Apply color jittering to the original image\n",
    "            color_jittered_image = cv2.cvtColor(original_image_rgb, cv2.COLOR_RGB2HSV)\n",
    "            \n",
    "            # Adjust brightness\n",
    "            brightness_factor = random.uniform(0.5, 1.5)\n",
    "            color_jittered_image[..., 2] = cv2.multiply(color_jittered_image[..., 2], brightness_factor)\n",
    "\n",
    "            # Adjust contrast\n",
    "            contrast_factor = random.uniform(0.5, 1.5)\n",
    "            color_jittered_image[..., 1] = cv2.multiply(color_jittered_image[..., 1], contrast_factor)\n",
    "\n",
    "            # Adjust hue\n",
    "            hue_factor = random.uniform(-10, 10)\n",
    "            color_jittered_image[..., 0] = (color_jittered_image[..., 0] + hue_factor) % 180\n",
    "\n",
    "            # Adjust saturation\n",
    "            saturation_factor = random.uniform(0.5, 1.5)\n",
    "            color_jittered_image[..., 1] = cv2.multiply(color_jittered_image[..., 1], saturation_factor)\n",
    "\n",
    "            # Convert back to RGB\n",
    "            color_jittered_image_rgb = cv2.cvtColor(color_jittered_image, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "            # Save color-jittered image to the augmented database in RGB format\n",
    "            color_jittered_image_bytes = pickle.dumps(color_jittered_image_rgb)\n",
    "            save_image_to_database(cursor_augmented, target, name, color_jittered_image_bytes)\n",
    "\n",
    "            jittered_images_count += 1\n",
    "            \n",
    "            # Enhance edges using Laplacian filter\n",
    "            enhanced_image = enhance_edges(original_image_rgb)\n",
    "\n",
    "            # Save enhanced image to the augmented database in RGB format\n",
    "            enhanced_image_bytes = pickle.dumps(enhanced_image)\n",
    "            save_image_to_database(cursor_augmented, target, name, enhanced_image_bytes)\n",
    "\n",
    "            enhanced_images_count += 1\n",
    "            \n",
    "    # Process each image for the person (if the person has more than 50 images)\n",
    "    else:\n",
    "        # Process each image for the person (up to 50 images if the person has more than 50 images)\n",
    "        for idx, row_original in enumerate(person_images_original[:max_images_to_process]):\n",
    "            target, _, original_image_bytes = row_original\n",
    "\n",
    "            # Convert the image bytes back to a NumPy array\n",
    "            original_image = pickle.loads(original_image_bytes)\n",
    "\n",
    "            # Save original image to the augmented database in RGB format\n",
    "            original_image_rgb = (original_image * 255).astype('uint8')\n",
    "            original_image_bytes = pickle.dumps(original_image_rgb)\n",
    "            save_image_to_database(cursor_augmented, target, name, original_image_bytes)\n",
    "            # Increment original images count\n",
    "            original_images_count += 1\n",
    "\n",
    "# Iterate through all raw images in the raw dataset\n",
    "for name in tqdm(unique_names, desc='Processing raw images'):\n",
    "    # Retrieve raw image data for the current person from the original database\n",
    "    cursor_raw.execute('SELECT target, name, raw_image FROM faces WHERE name = ?', (name,))\n",
    "    person_raw_images = cursor_raw.fetchall()\n",
    "\n",
    "    # Determine the number of images to process for this person\n",
    "    max_images_to_process = min(50, len(person_raw_images))\n",
    "\n",
    "        # Process images if there are 70 or fewer images\n",
    "    if len(person_raw_images) <= 30:\n",
    "        for idx, raw_image_row in enumerate(person_raw_images):\n",
    "            target, _, raw_image_bytes = raw_image_row\n",
    "\n",
    "            # Convert the raw image bytes back to a NumPy array\n",
    "            raw_image = pickle.loads(raw_image_bytes)\n",
    "            raw_image_bgr = cv2.cvtColor(raw_image, cv2.COLOR_RGB2BGR)\n",
    "     \n",
    "            # Normalize pixel values to [0, 1]\n",
    "            raw_image_normal = raw_image_bgr / 255.0\n",
    "\n",
    "            # Convert the image to tensor and apply transformations\n",
    "            #raw_image_tensor = trans(Image.fromarray((raw_image_rgb * 255).astype('uint8')).convert('RGB')).unsqueeze(0)\n",
    "            aged_face = apply_pretrained_model(raw_image_normal)\n",
    "\n",
    "            # Detect faces in the aged image\n",
    "            faces = detector.detect_faces(aged_face)\n",
    "\n",
    "            # Set a minimum face size threshold\n",
    "            min_face_size = 100\n",
    "            filtered_faces = [face for face in faces if face['box'][2] > min_face_size and face['box'][3] > min_face_size]\n",
    "\n",
    "            # Use the largest detected face (if any)\n",
    "            if filtered_faces:\n",
    "               \n",
    "                main_face = max(filtered_faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "                x, y, w, h = main_face['box']\n",
    "\n",
    "                # Check if the face coordinates are valid\n",
    "                if w > 0 and h > 0:\n",
    "                    # Crop the face from the aged image\n",
    "                    cropped_face = aged_face[y:y+h, x:x+w]\n",
    "\n",
    "                    # Save the cropped face to the database\n",
    "                    aged_face_bytes = pickle.dumps(cropped_face)\n",
    "                    save_image_to_database(cursor_augmented, target, name, aged_face_bytes)\n",
    "\n",
    "                    # Increment original images count\n",
    "                    aged_images_count += 1\n",
    "                else:\n",
    "                    print(\"Invalid face coordinates or empty face region.\")\n",
    "            else:\n",
    "                print(\"No faces detected in the aged image.\")\n",
    "\n",
    "\n",
    "# Commit the changes to the augmented database\n",
    "conn_augmented.commit()\n",
    "\n",
    "# Retrieve data from the augmented database\n",
    "cursor_augmented.execute('SELECT target, name, image FROM faces')\n",
    "rows_augmented = cursor_augmented.fetchall()\n",
    "\n",
    "# Print the total number of images in the augmented dataset\n",
    "total_images_augmented = len(rows_augmented)\n",
    "print(f'Total number of images in the augmented dataset: {total_images_augmented}')\n",
    "print(f'Total number of original images in the augmented dataset: {original_images_count}')\n",
    "print(f'Total number of flipped images in the augmented dataset: {flipped_images_count}')\n",
    "print(f'Total number of rotated images in the augmented dataset: {rotated_images_count}')\n",
    "print(f'Total number of color jittered images in the augmented dataset: {jittered_images_count}')\n",
    "print(f'Total number of edge enhanced images in the augmented dataset: {enhanced_images_count}')\n",
    "print(f'Total number of aged images in the augmented dataset: {aged_images_count}')\n",
    "\n",
    "# Close the connections\n",
    "conn_original.close()\n",
    "conn_augmented.close()\n",
    "conn_raw.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
