{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the data from lfw dataset set is augmented using techniques such as flipping, dynamic rotation, color jittering, \n",
    "# and edge enhancement. The augmentation techniques are applied to training data which contains people with min 20 images.\n",
    "\n",
    "import sqlite3\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import imutils\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data using sklearn\n",
    "lfw_dataset = fetch_lfw_people(data_home='./LFW/', min_faces_per_person=10, download_if_missing=True, color=True)\n",
    "\n",
    "# Get the path to the raw images\n",
    "raw_images_path = os.path.join('./LFW/', \"lfw_home/lfw_funneled\")\n",
    "\n",
    "# Load raw images\n",
    "raw_images = []\n",
    "raw_names = os.listdir(raw_images_path)\n",
    "\n",
    "# Connecting to the SQLite database for original images \n",
    "conn_original = sqlite3.connect('../Datasets/lfw_dataset.db')\n",
    "cursor_original = conn_original.cursor()\n",
    "\n",
    "# Connecting to the SQLite database for augmented images\n",
    "conn_augmented = sqlite3.connect('../Datasets/lfw_augmented_dataset.db')\n",
    "cursor_augmented = conn_augmented.cursor()\n",
    "\n",
    "# Connecting to the SQLite database for raw images\n",
    "conn_raw = sqlite3.connect('../Datasets/lfw_raw_dataset.db')\n",
    "cursor_raw = conn_raw.cursor()\n",
    "\n",
    "# Connecting to the SQLite database for retrain images \n",
    "conn_retrain = sqlite3.connect('../Datasets/retrain_dataset.db')\n",
    "cursor_retrain = conn_retrain.cursor()\n",
    "\n",
    "# Drop the existing 'faces' table if it exists in the original database\n",
    "cursor_original.execute('DROP TABLE IF EXISTS faces')\n",
    "\n",
    "# Drop the existing 'faces' table if it exists in the augmented database\n",
    "cursor_augmented.execute('DROP TABLE IF EXISTS faces')\n",
    "\n",
    "# Drop the existing 'faces' table if it exists in the raw images database\n",
    "cursor_raw.execute('DROP TABLE IF EXISTS faces')\n",
    "\n",
    "# Creating a new 'faces' table in the augmented database\n",
    "cursor_augmented.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS faces (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        target INTEGER,\n",
    "        name TEXT NOT NULL,\n",
    "        image BLOB NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Creating a new 'faces' table in the original database\n",
    "cursor_original.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS faces (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        target INTEGER,\n",
    "        name TEXT NOT NULL,\n",
    "        image BLOB NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Creating a new 'faces' table in the raw images database\n",
    "cursor_raw.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS faces (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        target INTEGER,\n",
    "        name TEXT NOT NULL,\n",
    "        raw_image BLOB NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "\n",
    "image_index = -1\n",
    "total_images = 0\n",
    "total_raw_images = 0\n",
    "\n",
    "target_image_count = {}\n",
    "max_images_per_target = 300  # Maximum number of images per target\n",
    "\n",
    "# Inserting the targets, names, and images into the table (lfw_dataset)\n",
    "for image_index, images in enumerate(lfw_dataset.images):\n",
    "    # Convert the image data to bytes\n",
    "    rgb_image = (images * 255).astype('uint8')\n",
    "    image_bytes = pickle.dumps(rgb_image)\n",
    "    total_images += 1\n",
    "\n",
    "    # Get the target index for the specified image\n",
    "    target_index = lfw_dataset.target[image_index]\n",
    "\n",
    "    # Check if the target has already reached the limit\n",
    "    if target_index not in target_image_count:\n",
    "        target_image_count[target_index] = 0\n",
    "\n",
    "    # Get the corresponding name from target_names\n",
    "    name = lfw_dataset.target_names[target_index]\n",
    "\n",
    "    # Insert the record into the lfw_dataset.db with target as id\n",
    "    conn_original.execute(\"INSERT INTO faces (target, name, image) VALUES (?, ?, ?)\", (int(target_index), name, image_bytes))\n",
    "\n",
    "    # Increment the image count for the target\n",
    "    target_image_count[target_index] += 1\n",
    "\n",
    "# Commit the changes to the original database\n",
    "conn_original.commit()\n",
    "\n",
    "# Retrieve data from the original database\n",
    "cursor_original.execute('SELECT target, name, image FROM faces')\n",
    "rows_lfw = cursor_original.fetchall()\n",
    "\n",
    "# Move 10% of the images per person to the retrain_dataset.db database\n",
    "for target in set(row[0] for row in rows_lfw):\n",
    "    target_images = [row for row in rows_lfw if row[0] == target]\n",
    "    num_images_to_move = int(len(target_images) * 0.10)\n",
    "    target_images_to_move = target_images[:num_images_to_move]\n",
    "\n",
    "    for row in target_images_to_move:\n",
    "        target, name, image_bytes = row\n",
    "        cursor_retrain.execute(\"INSERT INTO faces (target, name, image) VALUES (?, ?, ?)\", (target, name, image_bytes))\n",
    "\n",
    "# Commit the changes to the retrain_dataset.db database\n",
    "conn_retrain.commit()\n",
    "\n",
    "# Iterate through all people in the dataset\n",
    "for target_index, name in enumerate(lfw_dataset.target_names):\n",
    "    # Replace spaces with underscores in the name for directory lookup\n",
    "    raw_image_directory_name = name.replace(\" \", \"_\")\n",
    "\n",
    "    # Find the matching raw image directory\n",
    "    raw_image_path = os.path.join(raw_images_path, raw_image_directory_name)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(raw_image_path):\n",
    "        # Iterate through all raw images in the directory\n",
    "        for raw_image_name in os.listdir(raw_image_path):\n",
    "            # Exclude images containing \"original\"\n",
    "            if \"original\" not in raw_image_name:\n",
    "                raw_image_file = os.path.join(raw_image_path, raw_image_name)\n",
    "                raw_image = cv2.imread(raw_image_file)\n",
    "\n",
    "                # Convert the raw image to bytes\n",
    "                raw_image_bytes = pickle.dumps(raw_image, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                total_raw_images += 1\n",
    "\n",
    "                # Insert the record into the database with target as id\n",
    "                cursor_raw.execute(\"INSERT INTO faces (target, name, raw_image) VALUES (?, ?, ?)\",\n",
    "                                        (int(target_index), name, raw_image_bytes))\n",
    "    else:\n",
    "        # Handle the case where the directory does not exist\n",
    "        print(f\"No raw image directory found for {name}\")\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn_raw.commit()\n",
    "\n",
    "# Print the total number of images and raw images extracted\n",
    "print(f\"Total number of images: {total_images}\")\n",
    "print(f\"Total number of raw images: {total_raw_images}\")\n",
    "\n",
    "# Retrieve data from the database\n",
    "cursor_original.execute('SELECT target, name, image FROM faces')\n",
    "rows = cursor_original.fetchall()\n",
    "\n",
    "# Separate targets, names, and images\n",
    "targets = [row[0] for row in rows]\n",
    "names = [row[1] for row in rows]\n",
    "images = [pickle.loads(row[2]) for row in rows]\n",
    "\n",
    "# Split the remaining data into training (60%) and temp (40%)\n",
    "X_train, X_temp, y_train, y_temp, train_names, temp_names = train_test_split(\n",
    "    images, targets, names, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Split the temp data into validation (50%) and test (50%)\n",
    "X_val, X_test, y_val, y_test, val_names, test_names = train_test_split(\n",
    "    X_temp, y_temp, temp_names, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Insert the split data into separate tables (training, validation, testing)\n",
    "def insert_data_into_table_original(images, targets, names, table_name, cursor):\n",
    "    for i in range(len(images)):\n",
    "        image_bytes = pickle.dumps(images[i])\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (target, name, image) VALUES (?, ?, ?)\", (targets[i], names[i], image_bytes))\n",
    "\n",
    "# Insert the split data into separate tables (training, validation, testing)\n",
    "def insert_data_into_table(images, targets, names, table_name, cursor):\n",
    "    for i in range(len(images)):\n",
    "        # Convert the image to RGB format\n",
    "        #rgb_image = cv2.cvtColor(images[i], cv2.COLOR_GRAY2RGB)\n",
    "        rgb_image = (images[i] * 255).astype('uint8')\n",
    "        image_bytes = pickle.dumps(rgb_image)\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (target, name, image) VALUES (?, ?, ?)\", (targets[i], names[i], image_bytes))\n",
    "\n",
    "# Create tables for training, validation, and testing\n",
    "cursor_original.execute('CREATE TABLE IF NOT EXISTS faces_train (target INT, name TEXT NOT NULL, image BLOB NOT NULL)')\n",
    "cursor_original.execute('CREATE TABLE IF NOT EXISTS faces_val (target INT, name TEXT NOT NULL, image BLOB NOT NULL)')\n",
    "cursor_original.execute('CREATE TABLE IF NOT EXISTS faces_test (target INT, name TEXT NOT NULL, image BLOB NOT NULL)')\n",
    "\n",
    "# Insert data into the tables\n",
    "insert_data_into_table_original(X_train, y_train, train_names, 'faces_train', cursor_original)\n",
    "insert_data_into_table(X_val, y_val, val_names, 'faces_val', cursor_original)\n",
    "insert_data_into_table(X_test, y_test, test_names, 'faces_test', cursor_original)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn_original.commit()\n",
    "\n",
    "# Execute SQL queries to count the number of images in each table\n",
    "cursor_original.execute('SELECT COUNT(*) FROM faces_train')\n",
    "num_train_images = cursor_original.fetchone()[0]\n",
    "print(f'Number of images in faces_train table: {num_train_images}')\n",
    "\n",
    "cursor_original.execute('SELECT COUNT(*) FROM faces_val')\n",
    "num_val_images = cursor_original.fetchone()[0]\n",
    "print(f'Number of images in faces_val table: {num_val_images}')\n",
    "\n",
    "cursor_original.execute('SELECT COUNT(*) FROM faces_test')\n",
    "num_test_images = cursor_original.fetchone()[0]\n",
    "print(f'Number of images in faces_test table: {num_test_images}')\n",
    "\n",
    "# Retrieve unique names from the test table original database\n",
    "cursor_original.execute('SELECT DISTINCT name FROM faces')\n",
    "unique_names = [row[0] for row in cursor_original.fetchall()]\n",
    "\n",
    "# Retrieve data from the original database\n",
    "cursor_original.execute('SELECT target, name, image FROM faces')\n",
    "rows_original = cursor_original.fetchall()\n",
    "\n",
    "# Implementation of a Residual Block with two convolutional layers, batch normalization, ReLU activation, and a shortcut connection for gradient flow.\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.BatchNorm2d(in_features),\n",
    "                      nn.ReLU(),\n",
    "                      nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.BatchNorm2d(in_features)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "    \n",
    "\n",
    "# Implementation of a generator neural network with an initial convolution block, downsampling, residual blocks, upsampling, and a final output layer using reflection padding and batch normalization. \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(3, ngf, 7),\n",
    "                 nn.BatchNorm2d(ngf),\n",
    "                 nn.ReLU()]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = ngf\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                      nn.BatchNorm2d(out_features),\n",
    "                      nn.ReLU()]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                      nn.BatchNorm2d(out_features),\n",
    "                      nn.ReLU()]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(ngf, 3, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "# Apply a pre-trained age progression model to an input image using a Generator, including loading the model, image transformations, and postprocessing.\n",
    "def apply_pretrained_model(image):\n",
    "\n",
    "    # Load the age progression model\n",
    "    model = Generator(ngf=32, n_residual_blocks=9)\n",
    "    ckpt = torch.load('state_dict.pth', map_location='cpu')\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    # Define image transformations\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    image = trans(Image.fromarray((image * 255).astype('uint8')).convert('RGB')).unsqueeze(0)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        result = model(image)\n",
    "    \n",
    "    # Convert the result back to a NumPy array\n",
    "    result = result.squeeze().cpu().numpy().transpose((1, 2, 0))\n",
    "   \n",
    "    # Postprocess if necessary (e.g., denormalization)\n",
    "    result = ((result + 1) / 2.0 * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "    return result\n",
    "\n",
    "# Convert BGR to RGB\n",
    "def convert_to_rgb(image_data):\n",
    "    rgb_image = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_image\n",
    "\n",
    "#save images to database\n",
    "def save_image_to_database(cursor, target, name, image_bytes):\n",
    "\n",
    "    cursor.execute(\"INSERT INTO faces (target, name, image) VALUES (?, ?, ?)\", (int(target), name, image_bytes))\n",
    "\n",
    "# Create an instance of the MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Initialize counters\n",
    "original_images_count = 0\n",
    "flipped_images_count = 0\n",
    "rotated_images_count = 0\n",
    "jittered_images_count = 0\n",
    "enhanced_images_count = 0\n",
    "aged_images_count = 0\n",
    "\n",
    "# Function for edge enhancement using Laplacian filter\n",
    "def enhance_edges(image):\n",
    "    # Apply Laplacian filter\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    sharp_image = np.clip(image - 0.7 * laplacian, 0, 255).astype('uint8')\n",
    "    return sharp_image\n",
    "\n",
    "# Process each image for the person\n",
    "for name in tqdm(unique_names, desc='Processing images'):\n",
    "    # Retrieve data for the current person from the original database\n",
    "    cursor_original.execute('SELECT target, name, image FROM faces_train WHERE name = ?', (name,))\n",
    "    person_images_original = cursor_original.fetchall()\n",
    "\n",
    "    for idx, row_original in enumerate(person_images_original):\n",
    "        target, _, original_image_bytes = row_original\n",
    "\n",
    "        # Convert the image bytes back to a NumPy array\n",
    "        original_image = pickle.loads(original_image_bytes)\n",
    "\n",
    "        # Save original image to the augmented database in RGB format\n",
    "        original_image_rgb = (original_image * 255).astype('uint8')\n",
    "        original_image_bytes = pickle.dumps(original_image_rgb)\n",
    "        save_image_to_database(cursor_augmented, target, name, original_image_bytes)\n",
    "\n",
    "        # Increment original images count\n",
    "        original_images_count += 1\n",
    "\n",
    "        # Save flipped image to the augmented database in RGB format\n",
    "        flipped_image = cv2.flip(original_image_rgb, 1)\n",
    "        flipped_image_bytes = pickle.dumps(flipped_image)\n",
    "        save_image_to_database(cursor_augmented, target, name, flipped_image_bytes)\n",
    "\n",
    "        flipped_images_count += 1\n",
    "\n",
    "        # Apply dynamic rotation to the original image\n",
    "        rotation_angle = random.uniform(-15, 15)  # Random rotation angle between -30 and 30 degrees\n",
    "        rotated_image = imutils.rotate(original_image_rgb, angle=rotation_angle)\n",
    "\n",
    "        # Save rotated image to the augmented database in RGB format\n",
    "        rotated_image_bytes = pickle.dumps(rotated_image)\n",
    "        save_image_to_database(cursor_augmented, target, name, rotated_image_bytes)\n",
    "\n",
    "        rotated_images_count += 1\n",
    "        \n",
    "        # Apply color jittering to the original image\n",
    "        color_jittered_image = cv2.cvtColor(original_image_rgb, cv2.COLOR_RGB2HSV)\n",
    "            \n",
    "        # Adjust brightness\n",
    "        brightness_factor = random.uniform(0.5, 1.5)\n",
    "        color_jittered_image[..., 2] = cv2.multiply(color_jittered_image[..., 2], brightness_factor)\n",
    "\n",
    "        # Adjust contrast\n",
    "        contrast_factor = random.uniform(0.5, 1.5)\n",
    "        color_jittered_image[..., 1] = cv2.multiply(color_jittered_image[..., 1], contrast_factor)\n",
    "\n",
    "        # Adjust hue\n",
    "        hue_factor = random.uniform(-10, 10)\n",
    "        color_jittered_image[..., 0] = (color_jittered_image[..., 0] + hue_factor) % 180\n",
    "\n",
    "        # Adjust saturation\n",
    "        saturation_factor = random.uniform(0.5, 1.5)\n",
    "        color_jittered_image[..., 1] = cv2.multiply(color_jittered_image[..., 1], saturation_factor)\n",
    "\n",
    "        # Convert back to RGB\n",
    "        color_jittered_image_rgb = cv2.cvtColor(color_jittered_image, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "        # Save color-jittered image to the augmented database in RGB format\n",
    "        color_jittered_image_bytes = pickle.dumps(color_jittered_image_rgb)\n",
    "        save_image_to_database(cursor_augmented, target, name, color_jittered_image_bytes)\n",
    "\n",
    "        jittered_images_count += 1\n",
    "        \n",
    "        # Enhance edges using Laplacian filter\n",
    "        enhanced_image = enhance_edges(original_image_rgb)\n",
    "\n",
    "        # Save enhanced image to the augmented database in RGB format\n",
    "        enhanced_image_bytes = pickle.dumps(enhanced_image)\n",
    "        save_image_to_database(cursor_augmented, target, name, enhanced_image_bytes)\n",
    "\n",
    "        enhanced_images_count += 1\n",
    "     \n",
    "\n",
    "# Get the list of unique names from faces_train table\n",
    "cursor_original.execute('SELECT DISTINCT name FROM faces_train')\n",
    "train_names_set = set(row[0] for row in cursor_original.fetchall())\n",
    "\n",
    "# Iterate through all raw images in the raw dataset\n",
    "for name in tqdm(unique_names, desc='Processing raw images'):\n",
    "\n",
    "     # Check if the current person exists in the faces_train table\n",
    "    if name in train_names_set:\n",
    "        # Retrieve the number of images for the current person from the faces_train table\n",
    "        cursor_original.execute('SELECT COUNT(*) FROM faces_train WHERE name = ?', (name,))\n",
    "        num_images_in_train = cursor_original.fetchone()[0]\n",
    "\n",
    "        # Retrieve raw image data for the current person from the original database\n",
    "        cursor_raw.execute('SELECT target, name, raw_image FROM faces WHERE name = ?', (name,))\n",
    "        person_raw_images = cursor_raw.fetchall()\n",
    "\n",
    "        # Process each raw image for the current person\n",
    "        for idx, raw_image_row in enumerate(person_raw_images[:num_images_in_train]):\n",
    "            target, _, raw_image_bytes = raw_image_row\n",
    "\n",
    "            # Convert the raw image bytes back to a NumPy array\n",
    "            raw_image = pickle.loads(raw_image_bytes)\n",
    "            raw_image_bgr = cv2.cvtColor(raw_image, cv2.COLOR_RGB2BGR)\n",
    "     \n",
    "            # Normalize pixel values to [0, 1]\n",
    "            raw_image_normal = raw_image_bgr / 255.0\n",
    "\n",
    "            # Apply transformations\n",
    "            aged_face = apply_pretrained_model(raw_image_normal)\n",
    "\n",
    "            # Detect faces in the aged image\n",
    "            faces = detector.detect_faces(aged_face)\n",
    "\n",
    "            # Set a minimum face size threshold\n",
    "            min_face_size = 100\n",
    "            filtered_faces = [face for face in faces if face['box'][2] > min_face_size and face['box'][3] > min_face_size]\n",
    "\n",
    "            # Use the largest detected face (if any)\n",
    "            if filtered_faces:\n",
    "               \n",
    "                main_face = max(filtered_faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "                x, y, w, h = main_face['box']\n",
    "\n",
    "                # Check if the face coordinates are valid\n",
    "                if w > 0 and h > 0:\n",
    "                    # Crop the face from the aged image\n",
    "                    cropped_face = aged_face[y:y+h, x:x+w]\n",
    "\n",
    "                    # Resize the cropped face if needed\n",
    "                    if cropped_face.shape != (62, 47, 3):\n",
    "                        cropped_face = cv2.resize(cropped_face, (47, 62))\n",
    "\n",
    "                    # Ensure that the cropped face is in uint8 format\n",
    "                    cropped_face = cropped_face.astype(np.uint8)\n",
    "\n",
    "                    # Save the cropped face to the database\n",
    "                    aged_face_bytes = pickle.dumps(cropped_face)\n",
    "                    save_image_to_database(cursor_augmented, target, name, aged_face_bytes)\n",
    "\n",
    "                    # Increment original images count\n",
    "                    aged_images_count += 1\n",
    "                else:\n",
    "                    print(\"Invalid face coordinates or empty face region.\")\n",
    "            else:\n",
    "                print(\"No faces detected in the aged image.\")\n",
    "\n",
    "# Commit the changes to the augmented database\n",
    "conn_augmented.commit()\n",
    "\n",
    "conn_raw.close()\n",
    "\n",
    "# Specify the path to the database file\n",
    "database_path = \"lfw_raw_dataset.db\"\n",
    "\n",
    "# Check if the file exists before attempting to delete\n",
    "if os.path.exists(database_path):\n",
    "    # Attempt to remove the file\n",
    "    try:\n",
    "        os.remove(database_path)\n",
    "        print(f\"The database file '{database_path}' has been successfully deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting the database file: {e}\")\n",
    "else:\n",
    "    print(f\"The database file '{database_path}' does not exist.\")\n",
    "\n",
    "# Retrieve data from the augmented database\n",
    "cursor_augmented.execute('SELECT target, name, image FROM faces')\n",
    "rows_augmented = cursor_augmented.fetchall()\n",
    "\n",
    "# Retrieve data from the augmented database\n",
    "cursor_retrain.execute('SELECT target, name, image FROM faces')\n",
    "rows_retrain = cursor_retrain.fetchall()\n",
    "\n",
    "# Print the total number of images in the augmented dataset\n",
    "total_images_augmented = len(rows_augmented)\n",
    "\n",
    "total_images_retrain = len(rows_retrain)\n",
    "\n",
    "print(f'Total number of images in the augmented dataset: {total_images_augmented}')\n",
    "print(f'Total number of images in the retrain dataset: {total_images_retrain}')\n",
    "print(f'Total number of original images in the augmented dataset: {original_images_count}')\n",
    "print(f'Total number of flipped images in the augmented dataset: {flipped_images_count}')\n",
    "print(f'Total number of rotated images in the augmented dataset: {rotated_images_count}')\n",
    "print(f'Total number of color jittered images in the augmented dataset: {jittered_images_count}')\n",
    "print(f'Total number of edge enhanced images in the augmented dataset: {enhanced_images_count}')\n",
    "print(f'Total number of aged images in the augmented dataset: {aged_images_count}')\n",
    "# Close the connections\n",
    "conn_original.close()\n",
    "conn_augmented.close()\n",
    "conn_retrain.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
