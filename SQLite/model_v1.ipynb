{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "def load_dataset(database_path):\n",
    "     # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(database_path)\n",
    "\n",
    "    # Query to select all records from the faces table\n",
    "    query = \"SELECT * FROM faces\"\n",
    "\n",
    "    # Fetch records from the database into a Pandas DataFrame\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    df['image'] = df['image'].apply(lambda x: np.array(pickle.loads(x)))\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    # Convert image bytes to numpy array\n",
    "    num_classes = len(np.unique(df['target']))\n",
    "    return df, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size=0.2, random_state=0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['image'].values, df['target'].values, test_size=test_size, random_state=random_state)\n",
    "    # Convert the image arrays to a numpy array\n",
    "    X_train = np.array([np.array(img) for img in X_train])\n",
    "    X_test = np.array([np.array(img) for img in X_test])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Print the shapes of the resulting sets\n",
    "    print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    # Plot the first image in X_train\n",
    "    plt.imshow(X_train[0])\n",
    "    plt.title('First Image in X_train')\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_and_print_shapes(y_train, y_test):\n",
    "    y_train_categorical = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test_categorical = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    return y_train_categorical, y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def train_cnn_model(input_shape, num_classes, X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model):\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions(df, model, X_test, y_test, num_rows=5, num_cols=5, figsize=(20, 20)):\n",
    "    # Make predictions on the test set\n",
    "    predicted_probabilities = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    # Loop through the test set and visualize predictions\n",
    "    for i in range(num_rows * num_cols):\n",
    "        \n",
    "        actual_name = df['name'][np.where(df['target'].values == np.argmax(y_test, axis=1)[i])[0][0]]\n",
    "        predicted_name = df['name'][np.where(df['target'].values == predicted_classes[i])[0][0]] \n",
    "\n",
    "        axes[i].imshow(X_test[i])\n",
    "        axes[i].set_title(\"Prediction Class = {}\\nTrue Class = {}\".format(predicted_name, actual_name))\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, num_classes = load_dataset('lfw_dataset.db')\n",
    "X_train, X_test, y_train, y_test = split_dataset(df)\n",
    "\n",
    "y_train, y_test = preprocess_and_print_shapes(y_train, y_test)\n",
    "\n",
    "input_shape = (62, 47, 3)\n",
    "\n",
    "cnn_model = train_cnn_model(input_shape, num_classes, X_train, y_train, X_test, y_test)\n",
    "# Train the model\n",
    "get_accuracy(cnn_model)\n",
    "\n",
    "# Save the trained model\n",
    "cnn_model.save('trained_model.h5')\n",
    "\n",
    "#visualize the model on test set\n",
    "visualize_predictions(df, cnn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "\n",
    "def visualize_feature_maps(model, image):\n",
    "    \n",
    "    #Get indices of convolutional layers\n",
    "    conv_layer_indices = [i for i, layer in enumerate(model.layers) if isinstance(layer, Conv2D)]\n",
    "\n",
    "    #Create a list to store convolutional layers\n",
    "    conv_layers = [layer for layer in model.layers if isinstance(layer, Conv2D)]\n",
    "\n",
    "    #Create a new model containing only the convolutional layers\n",
    "    model2 = Model(inputs=model.inputs, outputs=[layer.output for layer in conv_layers])\n",
    "\n",
    "    #Expand the dimensions of the input to match the model's expected input shape\n",
    "    image = expand_dims(image, axis=0)\n",
    "\n",
    "    #Get the feature maps\n",
    "    feature_maps = model2.predict(image)\n",
    "    summed_feature_maps = [fmap_list.sum(axis=-1) for fmap_list in feature_maps]\n",
    "\n",
    "    #Plot the feature maps\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    layer_index = 0\n",
    "\n",
    "    for summed_fmap in summed_feature_maps:\n",
    "        ax = plt.subplot(len(conv_layers), 1, layer_index + 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(summed_fmap[0, :, :], cmap='gray')\n",
    "\n",
    "        layer_index += 1\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "visualize_feature_maps(cnn_model, X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
