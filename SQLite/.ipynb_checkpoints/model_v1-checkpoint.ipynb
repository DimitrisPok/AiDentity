{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "def load_dataset(database_path):\n",
    "     # Connect to the SQLite database\n",
    "    conn = sqlite3.connect('lfw_augmented_dataset.db')\n",
    "\n",
    "    # Query to select all records from the faces table\n",
    "    query = \"SELECT * FROM faces\"\n",
    "\n",
    "    # Fetch records from the database into a Pandas DataFrame\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    df['image'] = df['image'].apply(lambda x: np.array(pickle.loads(x)))\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    # Convert image bytes to numpy array\n",
    "    num_classes = len(np.unique(df['target']))\n",
    "    return df, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size=0.2, random_state=0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['image'].values, df['target'].values, test_size=test_size, random_state=random_state)\n",
    "    # Convert the image arrays to a numpy array\n",
    "    X_train = np.array([np.array(img) for img in X_train])\n",
    "    X_test = np.array([np.array(img) for img in X_test])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Print the shapes of the resulting sets\n",
    "    print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    # Plot the first image in X_train\n",
    "    plt.imshow(X_train[0])\n",
    "    plt.title('First Image in X_train')\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_and_print_shapes(y_train, y_test):\n",
    "    y_train_categorical = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test_categorical = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    return y_train_categorical, y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def train_cnn_model(input_shape, num_classes, X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions(df, model, X_test, y_test, num_rows=5, num_cols=5, figsize=(20, 20)):\n",
    "    # Make predictions on the test set\n",
    "    predicted_probabilities = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    # Loop through the test set and visualize predictions\n",
    "    for i in range(num_rows * num_cols):\n",
    "        \n",
    "        actual_name = df['name'][np.where(df['target'].values == np.argmax(y_test, axis=1)[i])[0][0]]\n",
    "        predicted_name = df['name'][np.where(df['target'].values == predicted_classes[i])[0][0]] \n",
    "\n",
    "        axes[i].imshow(X_test[i])\n",
    "        axes[i].set_title(\"Prediction Class = {}\\nTrue Class = {}\".format(predicted_name, actual_name))\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix)\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions on the test set\n",
    "    predicted_probabilities = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    # Check if y_test is one-hot encoded and convert it back to class labels\n",
    "    if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy1 = accuracy_score(y_test, predicted_classes)\n",
    "    print(\"Accuracy:\", accuracy1)\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(y_test, predicted_classes, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(y_test, predicted_classes, average='weighted')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_test, predicted_classes, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "    # Sum the values for TP, TN, FP, FN\n",
    "    TP = np.sum(np.diag(cm))\n",
    "    TN = np.sum(np.delete(np.delete(cm, np.arange(len(cm)), axis=0), np.arange(len(cm)), axis=1))\n",
    "    FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    FN = np.sum(cm, axis=1) - np.diag(cm)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"True Positives (TP):\", TP)\n",
    "    print(\"True Negatives (TN):\", TN)\n",
    "    print(\"False Positives (FP):\", np.sum(FP))\n",
    "    print(\"False Negatives (FN):\", np.sum(FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, num_classes = load_dataset('lfw_augmented_dataset.db')\n",
    "X_train, X_test, y_train, y_test = split_dataset(df)\n",
    "\n",
    "y_train, y_test = preprocess_and_print_shapes(y_train, y_test)\n",
    "\n",
    "input_shape = (62, 47, 3)\n",
    "\n",
    "cnn_model = train_cnn_model(input_shape, num_classes, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Save the trained model\n",
    "cnn_model.save('trained_model.h5')\n",
    "\n",
    "#visualize the model on test set\n",
    "visualize_predictions(df, cnn_model, X_test, y_test)\n",
    "\n",
    "#Evaluate the model\n",
    "evaluate_model(cnn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
