{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "def load_dataset(database_path):\n",
    "     # Connect to the SQLite database\n",
    "    conn = sqlite3.connect('lfw_augmented_dataset.db')\n",
    "\n",
    "    # Query to select all records from the faces table\n",
    "    query = \"SELECT * FROM faces\"\n",
    "\n",
    "    # Fetch records from the database into a Pandas DataFrame\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    df['image'] = df['image'].apply(lambda x: np.array(pickle.loads(x)))\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    # Convert image bytes to numpy array\n",
    "    num_classes = len(np.unique(df['target']))\n",
    "    return df, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size=0.2, random_state=0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['image'].values, df['target'].values, test_size=test_size, random_state=random_state)\n",
    "    # Convert the image arrays to a numpy array\n",
    "    X_train = np.array([np.array(img) for img in X_train])\n",
    "    X_test = np.array([np.array(img) for img in X_test])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Print the shapes of the resulting sets\n",
    "    print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    # Plot the first image in X_train\n",
    "    plt.imshow(X_train[0])\n",
    "    plt.title('First Image in X_train')\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_and_print_shapes(y_train, y_test):\n",
    "    y_train_categorical = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test_categorical = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    return y_train_categorical, y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def train_cnn_model(input_shape, num_classes, X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model):\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions(df, model, X_test, y_test, num_rows=5, num_cols=5, figsize=(20, 20)):\n",
    "    # Make predictions on the test set\n",
    "    predicted_probabilities = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    # Loop through the test set and visualize predictions\n",
    "    for i in range(num_rows * num_cols):\n",
    "        \n",
    "        actual_name = df['name'][np.where(df['target'].values == np.argmax(y_test, axis=1)[i])[0][0]]\n",
    "        predicted_name = df['name'][np.where(df['target'].values == predicted_classes[i])[0][0]] \n",
    "\n",
    "        axes[i].imshow(X_test[i])\n",
    "        axes[i].set_title(\"Prediction Class = {}\\nTrue Class = {}\".format(predicted_name, actual_name))\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix)\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions on the test set\n",
    "    predicted_probabilities = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "    # Check if y_test is one-hot encoded and convert it back to class labels\n",
    "    if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy1 = accuracy_score(y_test, predicted_classes)\n",
    "    print(\"Accuracy 1:\", accuracy1)\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(y_test, predicted_classes, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(y_test, predicted_classes, average='weighted')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_test, predicted_classes, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "    # Sum the values for TP, TN, FP, FN\n",
    "    TP = np.sum(np.diag(cm))\n",
    "    TN = np.sum(np.delete(np.delete(cm, np.arange(len(cm)), axis=0), np.arange(len(cm)), axis=1))\n",
    "    FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    FN = np.sum(cm, axis=1) - np.diag(cm)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"True Positives (TP):\", TP)\n",
    "    print(\"True Negatives (TN):\", TN)\n",
    "    print(\"False Positives (FP):\", np.sum(FP))\n",
    "    print(\"False Negatives (FN):\", np.sum(FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM faces': no such table: faces",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2264\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2264\u001b[0m     cur\u001b[39m.\u001b[39mexecute(sql, \u001b[39m*\u001b[39margs)\n\u001b[1;32m   2265\u001b[0m     \u001b[39mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: faces",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df, num_classes \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfw_augmented_dataset.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m split_dataset(df)\n\u001b[1;32m      4\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m preprocess_and_print_shapes(y_train, y_test)\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(database_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM faces\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Fetch records from the database into a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query, conn)\n\u001b[1;32m     20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(pickle\u001b[38;5;241m.\u001b[39mloads(x)))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Close the database connection\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39massert\u001b[39;00m dtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default\n\u001b[1;32m    485\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mread_query(\n\u001b[1;32m    487\u001b[0m         sql,\n\u001b[1;32m    488\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[1;32m    489\u001b[0m         params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    490\u001b[0m         coerce_float\u001b[39m=\u001b[39mcoerce_float,\n\u001b[1;32m    491\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[1;32m    492\u001b[0m         chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[1;32m    493\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    494\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    495\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2328\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   2318\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2319\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2328\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2329\u001b[0m     columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[1;32m   2331\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:2276\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2273\u001b[0m     \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39minner_exc\u001b[39;00m\n\u001b[1;32m   2275\u001b[0m ex \u001b[39m=\u001b[39m DatabaseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution failed on sql \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msql\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2276\u001b[0m \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM faces': no such table: faces"
     ]
    }
   ],
   "source": [
    "df, num_classes = load_dataset('lfw_augmented_dataset.db')\n",
    "X_train, X_test, y_train, y_test = split_dataset(df)\n",
    "\n",
    "y_train, y_test = preprocess_and_print_shapes(y_train, y_test)\n",
    "\n",
    "input_shape = (62, 47, 3)\n",
    "\n",
    "cnn_model = train_cnn_model(input_shape, num_classes, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Train the model\n",
    "get_accuracy(cnn_model)\n",
    "\n",
    "# Save the trained model\n",
    "cnn_model.save('trained_model.h5')\n",
    "\n",
    "#visualize the model on test set\n",
    "visualize_predictions(df, cnn_model, X_test, y_test)\n",
    "\n",
    "#Evaluate the model\n",
    "evaluate_model(cnn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
